"""
ECGé‡å»ºæ¨¡å‹å®šä¹‰

æ¶æ„: U-Net + å¤šä»»åŠ¡å¤´ + STN + ä¿¡å·è§£ç å™¨
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.models as models
from typing import Dict


class ChannelAttention(nn.Module):
    """é€šé“æ³¨æ„åŠ›æ¨¡å—"""
    def __init__(self, in_channels: int, reduction: int = 16):
        super().__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)
        self.fc = nn.Sequential(
            nn.Conv2d(in_channels, in_channels // reduction, 1, bias=False),
            nn.ReLU(inplace=True),
            nn.Conv2d(in_channels // reduction, in_channels, 1, bias=False)
        )
        self.sigmoid = nn.Sigmoid()
    
    def forward(self, x):
        avg_out = self.fc(self.avg_pool(x))
        max_out = self.fc(self.max_pool(x))
        out = self.sigmoid(avg_out + max_out)
        return x * out


class SpatialTransformerNetwork(nn.Module):
    """
    ç©ºé—´å˜æ¢ç½‘ç»œ - ç”¨äºå‡ ä½•æ ¡æ­£
    
    MPSå…¼å®¹ç‰ˆæœ¬ï¼šé¿å…ä½¿ç”¨AdaptiveAvgPool2d
    """
    def __init__(self, in_channels: int = 2048):
        super().__init__()
        self.in_channels = in_channels
        
        # ğŸ”¥ ä½¿ç”¨å…¨å·ç§¯ç½‘ç»œä»£æ›¿AdaptiveAvgPool
        self.localization = nn.Sequential(
            # é™ç»´
            nn.Conv2d(in_channels, 256, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(True),
            nn.Conv2d(256, 128, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(True),
            # å…¨å±€å¹³å‡æ± åŒ–ï¼ˆMPSæ”¯æŒï¼‰
            nn.AdaptiveAvgPool2d(1),  # æ± åŒ–åˆ°1x1ï¼Œè¿™ä¸ªMPSæ”¯æŒ
            nn.Flatten(),
            nn.Linear(128, 64),
            nn.ReLU(True),
            nn.Dropout(0.2),
            nn.Linear(64, 6)  # ä»¿å°„å˜æ¢6ä¸ªå‚æ•°
        )
        
        # åˆå§‹åŒ–ä¸ºå•ä½å˜æ¢
        self.localization[-1].weight.data.zero_()
        self.localization[-1].bias.data.copy_(
            torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float)
        )
    
    def forward(self, x):
        """
        Args:
            x: ç‰¹å¾å›¾ (B, C, H, W)
        Returns:
            theta: ä»¿å°„å˜æ¢çŸ©é˜µ (B, 2, 3)
        """
        theta = self.localization(x)  # (B, 6)
        theta = theta.view(-1, 2, 3)  # (B, 2, 3)
        return theta


class SignalDecoder(nn.Module):
    """
    ä¿¡å·è§£ç å™¨ï¼šä»æ ¡æ­£åçš„ç‰¹å¾å›¾ + åˆ†å‰²æ©ç  -> æ—¶é—´åºåˆ—ä¿¡å·
    """
    def __init__(self, feature_channels: int, num_leads: int, signal_length: int):
        super().__init__()
        self.num_leads = num_leads
        self.signal_length = signal_length
        
        # æ¯ä¸ªå¯¼è”çš„1Dç»†åŒ–ç½‘ç»œ
        self.lead_refiners = nn.ModuleList([
            nn.Sequential(
                nn.Conv1d(feature_channels, 128, kernel_size=7, padding=3),
                nn.BatchNorm1d(128),
                nn.ReLU(inplace=True),
                nn.Conv1d(128, 64, kernel_size=5, padding=2),
                nn.BatchNorm1d(64),
                nn.ReLU(inplace=True),
                nn.Conv1d(64, 1, kernel_size=3, padding=1)
            ) for _ in range(num_leads)
        ])
    
    def forward(self, features, wave_seg_logits, baseline_heatmaps):
        """
        Args:
            features: (B, C, H, W) æ ¡æ­£åçš„ç‰¹å¾
            wave_seg_logits: (B, 13, H, W) åˆ†å‰²logits
            baseline_heatmaps: (B, 12, H/k, W/k) åŸºçº¿çƒ­å›¾
        
        Returns:
            signal: (B, 12, T) é‡å»ºä¿¡å·
        """
        B, C, H, W = features.shape
        
        # Softmaxåˆ†å‰²æ©ç 
        wave_seg_prob = F.softmax(wave_seg_logits, dim=1)[:, 1:, :, :]  # (B, 12, H, W)
        
        # ä¸Šé‡‡æ ·åŸºçº¿çƒ­å›¾
        baseline_up = F.interpolate(
            baseline_heatmaps, 
            size=(H, W), 
            mode='bilinear', 
            align_corners=True
        )
        
        signals = []
        
        for lead_idx in range(self.num_leads):
            # æå–è¯¥å¯¼è”çš„åŠ æƒç‰¹å¾
            lead_mask = wave_seg_prob[:, lead_idx:lead_idx+1, :, :]  # (B, 1, H, W)
            baseline_mask = baseline_up[:, lead_idx:lead_idx+1, :, :]  # (B, 1, H, W)
            
            # ç»„åˆæ©ç 
            combined_mask = lead_mask * 0.3 + baseline_mask * 0.7  # (B, 1, H, W)
            
            # åŠ æƒç‰¹å¾
            weighted_features = features * combined_mask  # (B, C, H, W)
            
            # æ²¿å‚ç›´æ–¹å‘ï¼ˆyè½´ï¼‰åŠ æƒæ±‚å’Œï¼Œä¿ç•™æ°´å¹³ï¼ˆæ—¶é—´ï¼‰ä¿¡æ¯
            signal_1d = torch.sum(weighted_features, dim=2)  # (B, C, W)
            
            # å½’ä¸€åŒ–ï¼ˆé˜²æ­¢å…¨é›¶ï¼‰
            norm_factor = combined_mask.sum(dim=2).clamp(min=1e-6)  # (B, 1, W)
            signal_1d = signal_1d / norm_factor  # (B, C, W)
            
            # ğŸ”¥ ä¿®å¤NaN: æ£€æŸ¥å¹¶æ›¿æ¢å¼‚å¸¸å€¼
            if torch.isnan(signal_1d).any() or torch.isinf(signal_1d).any():
                signal_1d = torch.nan_to_num(signal_1d, nan=0.0, posinf=1.0, neginf=-1.0)
            
            # è°ƒæ•´é•¿åº¦åˆ°ç›®æ ‡ä¿¡å·é•¿åº¦
            if W != self.signal_length:
                signal_1d = F.interpolate(
                    signal_1d, 
                    size=self.signal_length, 
                    mode='linear', 
                    align_corners=True
                )
            
            # 1D CNNç»†åŒ–
            refined_signal = self.lead_refiners[lead_idx](signal_1d)  # (B, 1, T)
            signals.append(refined_signal)
        
        # åˆå¹¶æ‰€æœ‰å¯¼è”
        output = torch.cat(signals, dim=1)  # (B, 12, T)
        
        return output


class ECGReconstructionModel(nn.Module):
    """
    å®Œæ•´çš„ECGé‡å»ºæ¨¡å‹
    
    è¾“å…¥: (B, 3, H, W) ECGå›¾åƒ
    è¾“å‡º: 
        - wave_seg: (B, 13, H, W) å¯¼è”åˆ†å‰²ï¼ˆ12å¯¼è”+1èƒŒæ™¯ï¼‰
        - grid_mask: (B, 1, H, W) ç½‘æ ¼æ©ç 
        - baseline_heatmaps: (B, 12, H/16, W/16) åŸºçº¿çƒ­å›¾
        - theta: (B, 2, 3) å‡ ä½•å˜æ¢çŸ©é˜µ
        - signal: (B, 12, T) é‡å»ºä¿¡å·
        
    æ³¨æ„: å¦‚æœä½¿ç”¨pretrained=Trueï¼Œä¼šæœ‰è­¦å‘Šï¼Œè¿™æ˜¯æ­£å¸¸çš„
    """
    def __init__(self,
                 num_leads: int = 12,
                 signal_length: int = 5000,
                 pretrained: bool = True,
                 enable_stn: bool = True):  # ğŸ”¥ æ–°å¢å‚æ•°
        super().__init__()
        
        self.num_leads = num_leads
        self.signal_length = signal_length
        self.enable_stn = enable_stn  # æ˜¯å¦å¯ç”¨STN
        
        # ========== Stage 1: Encoder (ResNet-50 Backbone) ==========
        if pretrained:
            # ä½¿ç”¨æ–°çš„weightså‚æ•°ï¼ˆå…¼å®¹æ–°ç‰ˆtorchvisionï¼‰
            try:
                from torchvision.models import ResNet50_Weights
                resnet = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)
            except:
                # å›é€€åˆ°æ—§ç‰ˆæœ¬çš„pretrainedå‚æ•°
                import warnings
                warnings.filterwarnings('ignore', category=UserWarning)
                resnet = models.resnet50(pretrained=True)
        else:
            resnet = models.resnet50(pretrained=False)
        self.encoder1 = nn.Sequential(*list(resnet.children())[:4])   # 64 channels
        self.encoder2 = nn.Sequential(*list(resnet.children())[4:5])  # 256 channels
        self.encoder3 = nn.Sequential(*list(resnet.children())[5:6])  # 512 channels
        self.encoder4 = nn.Sequential(*list(resnet.children())[6:7])  # 1024 channels
        self.encoder5 = nn.Sequential(*list(resnet.children())[7:8])  # 2048 channels
        
        # é€šé“æ³¨æ„åŠ›
        self.ca5 = ChannelAttention(2048)
        self.ca4 = ChannelAttention(1024)
        self.ca3 = ChannelAttention(512)
        self.ca2 = ChannelAttention(256)
        self.ca1 = ChannelAttention(64)
        
        # ========== Stage 2: Decoder ==========
        self.up5 = nn.ConvTranspose2d(2048, 1024, kernel_size=2, stride=2)
        self.dec5 = self._make_decoder_block(1024 + 1024, 1024)
        
        self.up4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)
        self.dec4 = self._make_decoder_block(512 + 512, 512)
        
        self.up3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)
        self.dec3 = self._make_decoder_block(256 + 256, 256)
        
        self.up2 = nn.ConvTranspose2d(256, 64, kernel_size=2, stride=2)
        self.dec2 = self._make_decoder_block(64 + 64, 64)
        
        # ========== Stage 3: Task-Specific Heads ==========
        
        # 1. å¯¼è”åˆ†å‰²å¤´
        self.wave_seg_head = nn.Sequential(
            nn.Conv2d(64, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, num_leads + 1, 1)  # 12å¯¼è” + 1èƒŒæ™¯ç±»
        )
        
        # 2. ç½‘æ ¼æ©ç å¤´
        self.grid_head = nn.Sequential(
            nn.Conv2d(64, 32, 3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 1, 1),
            nn.Sigmoid()
        )
        
        # 3. åŸºçº¿çƒ­å›¾å¤´ï¼ˆä»ä¸­é—´å±‚ï¼‰
        self.baseline_head = nn.Sequential(
            nn.Conv2d(512, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, num_leads, 1),
            nn.Sigmoid()
        )
        
        # 4. å‡ ä½•æ ¡æ­£ç½‘ç»œ
        self.stn = SpatialTransformerNetwork(in_channels=2048)
        
        # 5. ä¿¡å·é‡å»ºç½‘ç»œ
        self.signal_decoder = SignalDecoder(
            feature_channels=64,
            num_leads=num_leads,
            signal_length=signal_length
        )
    
    def _make_decoder_block(self, in_channels, out_channels):
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:
        """
        Args:
            x: (B, 3, H, W) è¾“å…¥å›¾åƒ
        
        Returns:
            outputs: dict containing
                - wave_seg: (B, 13, H, W)
                - grid_mask: (B, 1, H, W)
                - baseline_heatmaps: (B, 12, H/16, W/16)
                - theta: (B, 2, 3)
                - signal: (B, 12, T)
                - rectified_features: (B, 64, H, W)
        """
        B, C, H, W = x.shape
        
        # ========== Encoding ==========
        e1 = self.encoder1(x)       # (B, 64, H/4, W/4)
        e2 = self.encoder2(e1)      # (B, 256, H/8, W/8)
        e3 = self.encoder3(e2)      # (B, 512, H/16, W/16)
        e4 = self.encoder4(e3)      # (B, 1024, H/32, W/32)
        e5 = self.encoder5(e4)      # (B, 2048, H/64, W/64)
        
        # ========== å‡ ä½•æ ¡æ­£ ==========
        theta = self.stn(e5)  # (B, 2, 3)
        
        # ========== Decoding ==========
        d5 = self.up5(self.ca5(e5))
        d5 = torch.cat([d5, self.ca4(e4)], dim=1)
        d5 = self.dec5(d5)
        
        d4 = self.up4(d5)
        d4 = torch.cat([d4, self.ca3(e3)], dim=1)
        d4 = self.dec4(d4)
        
        d3 = self.up3(d4)
        d3 = torch.cat([d3, self.ca2(e2)], dim=1)
        d3 = self.dec3(d3)
        
        d2 = self.up2(d3)
        # ğŸ”¥ ä¿®å¤ï¼šæ£€æŸ¥å°ºå¯¸æ˜¯å¦åŒ¹é…
        if d2.shape[2:] != e1.shape[2:]:
            # å¦‚æœå°ºå¯¸ä¸åŒ¹é…ï¼Œæ’å€¼åˆ°ç›¸åŒå°ºå¯¸
            d2 = F.interpolate(d2, size=e1.shape[2:], mode='bilinear', align_corners=True)
        d2 = torch.cat([d2, self.ca1(e1)], dim=1)
        d2 = self.dec2(d2)  # (B, 64, H/4, W/4)
        
        # ä¸Šé‡‡æ ·åˆ°åŸå§‹åˆ†è¾¨ç‡
        d_final = F.interpolate(d2, size=(H, W), mode='bilinear', align_corners=True)
        
        # ========== Task Outputs ==========
        
        # 1. å¯¼è”åˆ†å‰²
        wave_seg = self.wave_seg_head(d_final)  # (B, 13, H, W)
        
        # 2. ç½‘æ ¼æ©ç 
        grid_mask = self.grid_head(d_final)  # (B, 1, H, W)
        
        # 3. åŸºçº¿çƒ­å›¾ï¼ˆä»ä¸­é—´å±‚ï¼‰
        baseline_heatmaps = self.baseline_head(d4)  # (B, 12, H/16, W/16)
        
        # 4. å‡ ä½•æ ¡æ­£ç‰¹å¾
        # ğŸ”¥ ä¿®å¤ï¼šå®Œå…¨ç¦ç”¨STNçš„å‡ ä½•æ ¡æ­£ï¼Œé¿å…MPSçš„grid_sampleé—®é¢˜
        if self.enable_stn:
            # å¦‚æœå¯ç”¨STNï¼Œä»ç„¶è®¡ç®—thetaä½†ä¸åšgrid_sample
            # åªåœ¨CPU/CUDAä¸Šæ‰çœŸæ­£åšç©ºé—´å˜æ¢
            if self.training and d_final.device.type in ['cuda', 'cpu']:
                try:
                    grid_sample_grid = F.affine_grid(theta, d_final.size(), align_corners=True)
                    rectified_features = F.grid_sample(d_final, grid_sample_grid, align_corners=True)
                except (RuntimeError, NotImplementedError):
                    rectified_features = d_final
            else:
                # MPSæˆ–æ¨ç†æ¨¡å¼ï¼šä¸åšå‡ ä½•æ ¡æ­£
                rectified_features = d_final
        else:
            # STNå®Œå…¨ç¦ç”¨
            rectified_features = d_final
            # è¿”å›å•ä½çŸ©é˜µä½œä¸ºthetaï¼ˆé¿å…æŸå¤±å‡½æ•°æŠ¥é”™ï¼‰
            B = d_final.size(0)
            theta = torch.tensor([[1, 0, 0], [0, 1, 0]], dtype=torch.float32, device=d_final.device)
            theta = theta.unsqueeze(0).repeat(B, 1, 1)
        
        # 5. ä¿¡å·é‡å»º
        signal = self.signal_decoder(rectified_features, wave_seg, baseline_heatmaps)
        
        return {
            'wave_seg': wave_seg,
            'grid_mask': grid_mask,
            'baseline_heatmaps': baseline_heatmaps,
            'theta': theta,
            'signal': signal,
            'rectified_features': rectified_features
        }


# ========== æµ‹è¯•ä»£ç  ==========

if __name__ == "__main__":
    print("="*70)
    print("ECGé‡å»ºæ¨¡å‹æµ‹è¯•")
    print("="*70)
    
    # å¿½ç•¥torchvisionçš„è­¦å‘Š
    import warnings
    warnings.filterwarnings('ignore', category=UserWarning)
    
    # åˆ›å»ºæ¨¡å‹
    print("\nåˆ›å»ºæ¨¡å‹...")
    model = ECGReconstructionModel(
        num_leads=12,
        signal_length=5000,
        pretrained=False  # æµ‹è¯•æ—¶ä¸ç”¨é¢„è®­ç»ƒï¼Œé¿å…ä¸‹è½½
    )
    print("âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ")
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    print("\næµ‹è¯•å‰å‘ä¼ æ’­...")
    x = torch.randn(2, 3, 512, 672)  # Batch=2
    
    print(f"è¾“å…¥shape: {x.shape}")
    
    try:
        outputs = model(x)
        print("âœ“ å‰å‘ä¼ æ’­æˆåŠŸ")
    except Exception as e:
        print(f"âœ— å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        print("\nè°ƒè¯•ä¿¡æ¯:")
        
        # é€å±‚æµ‹è¯•æ‰¾å‡ºé—®é¢˜
        e1 = model.encoder1(x)
        print(f"  e1: {e1.shape}")
        e2 = model.encoder2(e1)
        print(f"  e2: {e2.shape}")
        e3 = model.encoder3(e2)
        print(f"  e3: {e3.shape}")
        e4 = model.encoder4(e3)
        print(f"  e4: {e4.shape}")
        e5 = model.encoder5(e4)
        print(f"  e5: {e5.shape}")
        
        raise e
    
    print("\næ¨¡å‹è¾“å‡º:")
    for key, value in outputs.items():
        if isinstance(value, torch.Tensor):
            print(f"  {key:20s}: {tuple(value.shape)}")
    
    # å‚æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"\næ¨¡å‹ç»Ÿè®¡:")
    print(f"  æ€»å‚æ•°é‡: {total_params:,}")
    print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    print(f"  æ¨¡å‹å¤§å°: {total_params * 4 / 1024 / 1024:.2f} MB (fp32)")
    
    print("\n" + "="*70)
    print("âœ“ æ¨¡å‹æµ‹è¯•é€šè¿‡ï¼")
    print("="*70)