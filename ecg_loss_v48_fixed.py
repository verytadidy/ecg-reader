"""
ECG V48 Loss Functions (å®Œå…¨ä¿®å¤ç‰ˆ)
ä¿®å¤å†…å®¹:
1. âœ… æ–°å¢æ³¢å½¢åˆ†å‰² Loss (WaveSegmentationLoss)
2. âœ… æ–°å¢è¾…åŠ©æ©ç æŠ‘åˆ¶æœºåˆ¶
3. âœ… ä¼˜åŒ–ä¿¡å·å›å½’ Loss (èƒŒæ™¯æŠ‘åˆ¶)
4. âœ… æ¸è¿›å¼æƒé‡è°ƒåº¦ç­–ç•¥
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, Tuple, Optional

class DiceLoss(nn.Module):
    """Dice Loss (é€‚ç”¨äºäºŒå€¼/å¤šç±»åˆ†å‰²)"""
    def __init__(self, smooth=1.0):
        super().__init__()
        self.smooth = smooth

    def forward(self, pred, target):
        # pred: (B, C, H, W) after sigmoid
        # target: (B, C, H, W)
        intersection = (pred * target).sum(dim=(2, 3))
        union = pred.sum(dim=(2, 3)) + target.sum(dim=(2, 3))
        dice_score = (2. * intersection + self.smooth) / (union + self.smooth)
        return 1 - dice_score.mean()


class FocalLoss(nn.Module):
    """Focal Loss (å¤„ç†ç±»åˆ«ä¸å¹³è¡¡)"""
    def __init__(self, alpha=0.25, gamma=2.0):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma

    def forward(self, pred, target):
        bce_loss = F.binary_cross_entropy(pred, target, reduction='none')
        pt = torch.exp(-bce_loss)
        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss
        return focal_loss.mean()


class SegmentationLoss(nn.Module):
    """é€šç”¨åˆ†å‰² Loss"""
    def __init__(self, use_focal=True):
        super().__init__()
        self.dice = DiceLoss()
        self.focal = FocalLoss() if use_focal else None

    def _align_target(self, pred, target):
        """å¯¹é½ target åˆ° pred çš„å°ºå¯¸"""
        if pred.shape[-2:] != target.shape[-2:]:
            target = F.interpolate(target, size=pred.shape[-2:], mode='nearest')
        
        # é€šé“å¯¹é½
        if pred.shape[1] == 1 and target.shape[1] > 1:
            target, _ = target.max(dim=1, keepdim=True)
        
        return target

    def forward(self, pred, target):
        target = self._align_target(pred, target)
        loss = self.dice(pred, target)
        if self.focal:
            loss += self.focal(pred, target)
        return loss


class WaveSegmentationLoss(nn.Module):
    """
    ğŸ†• æ³¢å½¢åˆ†å‰² Loss (è¯­ä¹‰åˆ†å‰²)
    å¤„ç†å•é€šé“è¯­ä¹‰æ©ç  (å€¼ 0-12)
    """
    def __init__(self, num_classes=13, ignore_index=0):
        super().__init__()
        self.num_classes = num_classes
        self.ignore_index = ignore_index
        self.ce_loss = nn.CrossEntropyLoss(ignore_index=ignore_index)

    def forward(self, pred_logits, target):
        """
        Args:
            pred_logits: (B, 12, H, W) - 12 ç±»çš„ logits
            target: (B, H, W) - å€¼èŒƒå›´ [0, 12]
        """
        # å¯¹é½å°ºå¯¸
        if pred_logits.shape[-2:] != target.shape[-2:]:
            pred_logits = F.interpolate(pred_logits, size=target.shape[-2:], 
                                         mode='bilinear', align_corners=False)
        
        # CrossEntropy Loss
        loss = self.ce_loss(pred_logits, target.long())
        
        return loss


class SignalRegressionLoss(nn.Module):
    """
    ä¿¡å·å›å½’ Loss (å¸¦èƒŒæ™¯æŠ‘åˆ¶)
    """
    def __init__(self, loss_type='l1', background_weight=0.1):
        super().__init__()
        self.criterion = nn.L1Loss(reduction='none') if loss_type == 'l1' else nn.MSELoss(reduction='none')
        self.bg_weight = background_weight

    def forward(self, pred_signals, gt_signals, valid_mask=None):
        """
        Args:
            pred_signals: (B, 12, W)
            gt_signals: (B, 12, W)
            valid_mask: (B, 12, W) - 1=ä¿¡å·åŒº, 0=èƒŒæ™¯åŒº
        """
        min_len = min(pred_signals.shape[-1], gt_signals.shape[-1])
        pred = pred_signals[..., :min_len]
        gt = gt_signals[..., :min_len]
        
        raw_loss = self.criterion(pred, gt)
        
        if valid_mask is not None:
            mask = valid_mask[..., :min_len]
            # ä¿¡å·åŒºæƒé‡ 1.0ï¼ŒèƒŒæ™¯åŒºæƒé‡ bg_weight
            weights = mask + (1.0 - mask) * self.bg_weight
            weighted_loss = raw_loss * weights
            return weighted_loss.mean()
        else:
            return raw_loss.mean()


class AuxiliarySuppressionLoss(nn.Module):
    """
    ğŸ†• è¾…åŠ©æ©ç æŠ‘åˆ¶ Loss
    ç¡®ä¿æ¨¡å‹åœ¨ auxiliary_mask=1 çš„åŒºåŸŸä¸è¾“å‡ºæ³¢å½¢
    """
    def __init__(self):
        super().__init__()

    def forward(self, pred_wave_seg, auxiliary_mask):
        """
        Args:
            pred_wave_seg: (B, 12, H, W) - æ³¢å½¢åˆ†å‰² logits
            auxiliary_mask: (B, H, W) - è¾…åŠ©åŒºåŸŸæ©ç  (0-1)
        """
        # å¯¹é½å°ºå¯¸
        if pred_wave_seg.shape[-2:] != auxiliary_mask.shape[-2:]:
            auxiliary_mask = F.interpolate(
                auxiliary_mask.unsqueeze(1), 
                size=pred_wave_seg.shape[-2:], 
                mode='bilinear', align_corners=False
            ).squeeze(1)
        
        # åœ¨ auxiliary åŒºåŸŸï¼Œæ‰€æœ‰ç±»åˆ«çš„æ¦‚ç‡åº”è¯¥è¶‹å‘äºå‡åŒ€åˆ†å¸ƒï¼ˆæ— ä¿¡å·ï¼‰
        # æˆ–è€…æ›´ç®€å•ï¼šåœ¨ auxiliary åŒºåŸŸï¼Œæ³¢å½¢åˆ†å‰²æ¦‚ç‡åº”è¯¥å¾ˆä½
        pred_probs = torch.softmax(pred_wave_seg, dim=1)[:, 1:, :, :]  # æ’é™¤ background
        
        # auxiliary_mask ä½œä¸ºæƒé‡ï¼Œåªæƒ©ç½šè¾…åŠ©åŒºåŸŸçš„æ³¢å½¢é¢„æµ‹
        aux_penalty = (pred_probs * auxiliary_mask.unsqueeze(1)).mean()
        
        return aux_penalty


class ProgressiveLeadLocalizationLossV48(nn.Module):
    """
    ğŸ”¥ å®Œæ•´çš„ç»„åˆ Loss (V48)
    """
    def __init__(self,
                 weight_coarse_baseline=1.0,
                 weight_text=1.0,
                 weight_wave_seg=5.0,        # ğŸ†• æ³¢å½¢åˆ†å‰²æƒé‡
                 weight_lead_baseline=5.0,   # ç²¾ç»†åŸºçº¿æƒé‡ï¼ˆæ ¸å¿ƒï¼‰
                 weight_signal=10.0,
                 weight_aux_suppress=0.5,    # ğŸ†• è¾…åŠ©æŠ‘åˆ¶æƒé‡
                 weight_ocr=0.5,
                 background_weight=0.1,
                 use_focal_loss=True):
        super().__init__()
        
        self.weights = {
            'coarse': weight_coarse_baseline,
            'text': weight_text,
            'wave_seg': weight_wave_seg,
            'fine': weight_lead_baseline,
            'signal': weight_signal,
            'aux_suppress': weight_aux_suppress,
            'ocr': weight_ocr
        }
        
        self.seg_loss_fn = SegmentationLoss(use_focal=use_focal_loss)
        self.wave_seg_loss_fn = WaveSegmentationLoss(num_classes=13, ignore_index=0)
        self.sig_loss_fn = SignalRegressionLoss(loss_type='l1', background_weight=background_weight)
        self.aux_suppress_fn = AuxiliarySuppressionLoss()

    def forward(self, outputs: Dict, targets: Dict) -> Tuple[torch.Tensor, Dict]:
        loss_dict = {}
        total_loss = 0.0
        
        # 1. ç²—åŸºçº¿ (H/16)
        if 'coarse_baseline' in outputs and 'baseline_coarse' in targets:
            l = self.seg_loss_fn(outputs['coarse_baseline'], targets['baseline_coarse'])
            loss_dict['loss_coarse'] = l
            total_loss += l * self.weights['coarse']
        
        # 2. æ–‡å­—æ©ç  (H/4)
        if 'text_masks' in outputs and 'text_multi' in targets:
            l = self.seg_loss_fn(outputs['text_masks'], targets['text_multi'])
            loss_dict['loss_text'] = l
            total_loss += l * self.weights['text']
        
        # 3. ğŸ†• æ³¢å½¢åˆ†å‰² (H/4)
        if 'wave_segmentation_logits' in outputs and 'wave_segmentation' in targets:
            l = self.wave_seg_loss_fn(outputs['wave_segmentation_logits'], targets['wave_segmentation'])
            loss_dict['loss_wave_seg'] = l
            total_loss += l * self.weights['wave_seg']
        
        # 4. ç²¾ç»†åŸºçº¿ (H/4) - æ ¸å¿ƒå®šä½
        if 'lead_baselines' in outputs and 'baseline_fine' in targets:
            l = self.seg_loss_fn(outputs['lead_baselines'], targets['baseline_fine'])
            loss_dict['loss_fine'] = l
            total_loss += l * self.weights['fine']
        
        # 5. ğŸ†• è¾…åŠ©æ©ç æŠ‘åˆ¶
        if 'wave_segmentation_logits' in outputs and 'auxiliary_mask' in targets:
            l = self.aux_suppress_fn(outputs['wave_segmentation_logits'], targets['auxiliary_mask'])
            loss_dict['loss_aux_suppress'] = l
            total_loss += l * self.weights['aux_suppress']
        
        # 6. OCR ä»»åŠ¡
        if 'ocr_maps' in outputs:
            if 'paper_speed_mask' in targets and 'gain_mask' in targets:
                # åˆå¹¶ä¸¤ä¸ª OCR ç›®æ ‡
                ocr_target = torch.stack([
                    targets['paper_speed_mask'],
                    targets['gain_mask']
                ], dim=1)  # (B, 2, H, W)
                
                l = self.seg_loss_fn(outputs['ocr_maps'], ocr_target)
                loss_dict['loss_ocr'] = l
                total_loss += l * self.weights['ocr']
        
        # 7. ä¿¡å·å›å½’
        if 'signals' in outputs and 'gt_signals' in targets:
            mask = targets.get('valid_mask', None)
            l = self.sig_loss_fn(outputs['signals'], targets['gt_signals'], mask)
            loss_dict['loss_signal'] = l
            total_loss += l * self.weights['signal']
        
        loss_dict['total_loss'] = total_loss
        return total_loss, loss_dict


class ProgressiveWeightScheduler:
    """
    ğŸ†• æ¸è¿›å¼æƒé‡è°ƒåº¦å™¨
    æ—©æœŸ: ä¸“æ³¨å®šä½ (baseline, wave_seg)
    åæœŸ: åŠ å¤§ä¿¡å·æƒé‡
    """
    def __init__(self, criterion, total_epochs=50, warmup_epochs=10):
        self.criterion = criterion
        self.total_epochs = total_epochs
        self.warmup_epochs = warmup_epochs
        
        # ä¿å­˜åˆå§‹æƒé‡
        self.initial_weights = criterion.weights.copy()

    def step(self, epoch):
        """æ ¹æ® epoch è°ƒæ•´æƒé‡"""
        if epoch < self.warmup_epochs:
            # Warmup é˜¶æ®µ: é«˜å®šä½æƒé‡ï¼Œä½ä¿¡å·æƒé‡
            ratio = epoch / self.warmup_epochs
            self.criterion.weights['signal'] = self.initial_weights['signal'] * (0.1 + 0.9 * ratio)
            self.criterion.weights['fine'] = self.initial_weights['fine'] * (1.5 - 0.5 * ratio)
        else:
            # æ­£å¸¸é˜¶æ®µ
            self.criterion.weights['signal'] = self.initial_weights['signal']
            self.criterion.weights['fine'] = self.initial_weights['fine']


# ========== æ¨¡å—æµ‹è¯• ==========
if __name__ == "__main__":
    print("Testing ECG Loss V48...")
    
    criterion = ProgressiveLeadLocalizationLossV48()
    scheduler = ProgressiveWeightScheduler(criterion, total_epochs=50, warmup_epochs=10)
    
    B, H, W = 2, 512, 2048
    
    # æ¨¡æ‹Ÿè¾“å‡º
    outputs = {
        'coarse_baseline': torch.sigmoid(torch.randn(B, 1, 32, 128)),
        'lead_baselines': torch.sigmoid(torch.randn(B, 12, 128, 512)),
        'wave_segmentation_logits': torch.randn(B, 12, 128, 512),
        'signals': torch.randn(B, 12, 512)
    }
    
    # æ¨¡æ‹Ÿç›®æ ‡
    targets = {
        'baseline_coarse': torch.zeros(B, 1, H, W),
        'baseline_fine': torch.zeros(B, 12, H, W),
        'text_multi': torch.zeros(B, 13, H, W),
        'wave_segmentation': torch.randint(0, 13, (B, H, W)),
        'auxiliary_mask': torch.zeros(B, H, W),
        'gt_signals': torch.zeros(B, 12, 512),
        'valid_mask': torch.cat([torch.ones(B, 12, 256), torch.zeros(B, 12, 256)], dim=-1)
    }
    
    # æµ‹è¯• Loss
    loss, loss_dict = criterion(outputs, targets)
    
    print(f"\nTotal Loss: {loss.item():.4f}")
    for k, v in loss_dict.items():
        if isinstance(v, torch.Tensor):
            print(f"  {k}: {v.item():.4f}")
    
    # æµ‹è¯•æƒé‡è°ƒåº¦
    print("\nTesting weight scheduler...")
    for epoch in [0, 5, 10, 20, 50]:
        scheduler.step(epoch)
        print(f"  Epoch {epoch}: signal_weight={criterion.weights['signal']:.2f}, "
              f"fine_weight={criterion.weights['fine']:.2f}")
    
    print("\nâœ“ Loss test passed!")