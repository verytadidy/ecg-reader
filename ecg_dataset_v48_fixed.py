"""
ECG V48 Dataset (å®Œå…¨ä¿®å¤ç‰ˆ)
ä¿®å¤å†…å®¹:
1. âœ… åŠ è½½ label_wave.npy (æ³¢å½¢åˆ†å‰²æ ‡ç­¾)
2. âœ… åŠ è½½ label_auxiliary.npy (è¾…åŠ©æ ‡è®°)
3. âœ… åŠ è½½ OCR æ©ç  (paper_speed, gain)
4. âœ… ä½¿ç”¨ metadata.time_range ç²¾ç¡®å¯¹é½ä¿¡å· ã€P0 ä¿®å¤ã€‘
5. âœ… ä¼˜åŒ–å†…å­˜ç¼“å­˜ç­–ç•¥
"""

import json
import numpy as np
import cv2
import torch
from pathlib import Path
from torch.utils.data import Dataset
import albumentations as A
from albumentations.pytorch import ToTensorV2
from PIL import Image
from typing import Tuple, Dict, Optional
import warnings

class ECGV48FixedDataset(Dataset):
    def __init__(self,
                 sim_root_dir: str,
                 csv_root_dir: str,
                 split: str = 'train',
                 target_size: Tuple[int, int] = (512, 2048),
                 target_fs: int = 500,
                 max_samples: Optional[int] = None,
                 augment: bool = False,
                 cache_images: bool = False):
        
        self.sim_root = Path(sim_root_dir)
        self.csv_root = Path(csv_root_dir)
        self.split = split
        self.target_size = target_size
        self.target_fs = target_fs
        self.augment = augment
        self.cache_images = cache_images
        self.cache_size_limit = 50
        
        self.cache = {}
        self.lead_names = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 
                           'V1', 'V2', 'V3', 'V4', 'V5', 'V6']
        
        self.samples = self._scan_samples(max_samples)
        self.transform = self._build_transform()

        print(f"\n{'='*60}")
        print(f"ECG Dataset V48 Fixed ({split})")
        print(f"Samples: {len(self.samples)}")
        print(f"Target Size: {target_size}")
        print(f"Image Cache: {'âœ… ON' if cache_images else 'âš ï¸ OFF'}")
        print(f"{'='*60}\n")

    def _scan_samples(self, max_samples):
        samples = []
        if not self.sim_root.exists():
            warnings.warn(f"Sim root not found: {self.sim_root}")
            return []
        
        dirs = sorted([d for d in self.sim_root.iterdir() if d.is_dir()])
        for d in dirs:
            sid = d.name
            required_files = [
                f"{sid}_dirty.png",
                f"{sid}_gt_signals.json",
                f"{sid}_metadata.json"
            ]
            if all((d / f).exists() for f in required_files):
                samples.append({'id': sid, 'dir': d})
            if max_samples and len(samples) >= max_samples:
                break
        return samples

    def _build_transform(self):
        if self.augment:
            return A.Compose([
                A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.05, p=0.4),
                A.GaussNoise(var_limit=(5.0, 15.0), p=0.3),
                A.CoarseDropout(max_holes=8, max_height=40, max_width=40, p=0.3),
                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
                ToTensorV2()
            ])
        else:
            return A.Compose([
                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
                ToTensorV2()
            ])

    def __len__(self):
        return len(self.samples)

    def _load_file(self, file_path, file_type, sample_id):
        """å¸¦ç¼“å­˜çš„æ–‡ä»¶åŠ è½½"""
        cache_key = f"{sample_id}_{file_path.name}"
        
        if cache_key in self.cache:
            return self.cache[cache_key]
        
        data = None
        try:
            if file_type == 'json':
                with open(file_path, 'r') as f:
                    data = json.load(f)
            elif file_type == 'npy':
                if file_path.exists():
                    data = np.load(file_path)
            elif file_type == 'img':
                data = np.array(Image.open(file_path).convert('RGB'))
        except Exception as e:
            warnings.warn(f"Failed to load {file_path}: {e}")
            return None
            
        if data is not None:
            if file_type == 'img':
                if self.cache_images:
                    self.cache[cache_key] = data
            else:
                self.cache[cache_key] = data
        
        if len(self.cache) > self.cache_size_limit:
            remove_count = int(self.cache_size_limit * 0.3)
            keys = list(self.cache.keys())
            for k in keys[:remove_count]:
                del self.cache[k]
            
        return data

    def __getitem__(self, idx):
        sample_info = self.samples[idx]
        sid = sample_info['id']
        sdir = sample_info['dir']
        
        h_tg, w_tg = self.target_size
        
        # ========== 1. åŠ è½½å›¾åƒ ==========
        img_path = sdir / f"{sid}_dirty.png"
        image = self._load_file(img_path, 'img', sid)
        if image is None:
            raise RuntimeError(f"Failed to load image: {img_path}")
        orig_h, orig_w = image.shape[:2]
        
        # ========== 2. åŠ è½½å…ƒæ•°æ® ==========
        meta = self._load_file(sdir / f"{sid}_metadata.json", 'json', sid)
        phys_params = meta.get('physical_params', {})
        gain = phys_params.get('gain_mm_mv', 10.0)
        speed = phys_params.get('paper_speed_mm_s', 25.0)
        lead_rois = meta.get('lead_rois', {})
        
        # ========== 3. åŠ è½½åŸºçº¿æ©ç  (12, H, W) ==========
        baseline_raw = self._load_file(sdir / f"{sid}_label_baseline.npy", 'npy', sid)
        if baseline_raw is not None and baseline_raw.shape[0] == 12:
            baseline_resized = np.zeros((12, h_tg, w_tg), dtype=np.float32)
            for i in range(12):
                baseline_resized[i] = cv2.resize(baseline_raw[i], (w_tg, h_tg), 
                                                  interpolation=cv2.INTER_LINEAR) / 255.0
        else:
            baseline_resized = np.zeros((12, h_tg, w_tg), dtype=np.float32)
            
        # ========== 4. åŠ è½½æ–‡å­—æ©ç  (13, H, W) ==========
        text_raw = self._load_file(sdir / f"{sid}_label_text_multi.npy", 'npy', sid)
        if text_raw is not None and text_raw.shape[0] == 13:
            text_resized = np.zeros((13, h_tg, w_tg), dtype=np.float32)
            for i in range(13):
                text_resized[i] = cv2.resize(text_raw[i], (w_tg, h_tg), 
                                              interpolation=cv2.INTER_NEAREST) / 255.0
        else:
            text_resized = np.zeros((13, h_tg, w_tg), dtype=np.float32)

        # ========== 5. åŠ è½½æ³¢å½¢åˆ†å‰²æ©ç  (H, W) ==========
        wave_seg_raw = self._load_file(sdir / f"{sid}_label_wave.npy", 'npy', sid)
        if wave_seg_raw is not None:
            wave_seg_resized = cv2.resize(wave_seg_raw, (w_tg, h_tg), 
                                           interpolation=cv2.INTER_NEAREST)
        else:
            wave_seg_resized = np.zeros((h_tg, w_tg), dtype=np.uint8)
            
        # ========== 6. åŠ è½½è¾…åŠ©æ©ç  (1, H, W) ==========
        aux_raw = self._load_file(sdir / f"{sid}_label_auxiliary.npy", 'npy', sid)
        if aux_raw is not None and len(aux_raw.shape) == 3:
            aux_resized = cv2.resize(aux_raw[0], (w_tg, h_tg), 
                                      interpolation=cv2.INTER_LINEAR) / 255.0
        else:
            aux_resized = np.zeros((h_tg, w_tg), dtype=np.float32)
            
        # ========== 7. åŠ è½½ OCR æ©ç  ==========
        ps_raw = self._load_file(sdir / f"{sid}_label_paper_speed.npy", 'npy', sid)
        if ps_raw is not None and len(ps_raw.shape) == 3:
            ps_resized = cv2.resize(ps_raw[0], (w_tg, h_tg), 
                                     interpolation=cv2.INTER_LINEAR) / 255.0
        else:
            ps_resized = np.zeros((h_tg, w_tg), dtype=np.float32)
            
        gain_raw = self._load_file(sdir / f"{sid}_label_gain.npy", 'npy', sid)
        if gain_raw is not None and len(gain_raw.shape) == 3:
            gain_resized = cv2.resize(gain_raw[0], (w_tg, h_tg), 
                                       interpolation=cv2.INTER_LINEAR) / 255.0
        else:
            gain_resized = np.zeros((h_tg, w_tg), dtype=np.float32)

        # ========== 8. ğŸ”¥ P0 ä¿®å¤ï¼šç²¾ç¡®ä¿¡å·å¯¹é½ ==========
        gt_data = self._load_file(sdir / f"{sid}_gt_signals.json", 'json', sid)
        
        feature_width = w_tg // 4  # ç‰¹å¾å›¾å®½åº¦
        target_signals = np.zeros((12, feature_width), dtype=np.float32)
        valid_mask = np.zeros((12, feature_width), dtype=np.float32)
        
        # è®¡ç®—åŸå§‹å›¾åƒåˆ°ç‰¹å¾å›¾çš„ç¼©æ”¾æ¯”ä¾‹
        scale_x = feature_width / orig_w
        scale_y = h_tg / orig_h  # è™½ç„¶ç”¨ä¸åˆ°ï¼Œä½†ä¿æŒä¸€è‡´æ€§
        
        for i, lead in enumerate(self.lead_names):
            # ä» GT JSON åŠ è½½åŸå§‹ä¿¡å·
            raw_sig = gt_data['signals'].get(lead, None)
            if raw_sig is None or len(raw_sig) == 0:
                continue
            raw_sig = np.array(raw_sig, dtype=np.float32)
            
            # ğŸ”¥ ä¿®å¤å…³é”®ç‚¹ï¼šä½¿ç”¨ RoI bbox çš„å®é™…å®½åº¦
            if lead in lead_rois and lead_rois[lead] is not None:
                roi_bbox = lead_rois[lead].get('bbox', None)
            else:
                roi_bbox = None
            
            if roi_bbox is None:
                # å¦‚æœæ²¡æœ‰ bboxï¼Œè·³è¿‡è¯¥å¯¼è”
                warnings.warn(f"Lead {lead} missing bbox in metadata")
                continue
            
            # bbox æ ¼å¼: [x1, y1, x2, y2] (åŸå§‹å›¾åƒåæ ‡)
            x1_orig, y1_orig, x2_orig, y2_orig = roi_bbox
            
            # è½¬æ¢åˆ°ç‰¹å¾å›¾åæ ‡
            x1_feat = int(x1_orig * scale_x)
            x2_feat = int(x2_orig * scale_x)
            
            # ç‰¹å¾å›¾ä¸Šçš„å¯¼è”å®½åº¦
            segment_len = x2_feat - x1_feat
            
            if segment_len <= 0:
                warnings.warn(f"Lead {lead} has invalid segment length: {segment_len}")
                continue
            
            # ç¡®ä¿ä¸è¶Šç•Œ
            x1_feat = max(0, x1_feat)
            x2_feat = min(feature_width, x2_feat)
            segment_len = x2_feat - x1_feat
            
            if segment_len > 0:
                # é‡é‡‡æ ·ä¿¡å·åˆ°ç‰¹å¾å›¾é•¿åº¦
                x_old = np.linspace(0, 1, len(raw_sig))
                x_new = np.linspace(0, 1, segment_len)
                resampled = np.interp(x_new, x_old, raw_sig)
                
                # å¡«å……åˆ°ç›®æ ‡æ•°ç»„
                target_signals[i, x1_feat:x2_feat] = resampled
                valid_mask[i, x1_feat:x2_feat] = 1.0
            
        # ========== 9. å›¾åƒå¢å¼ºä¸è½¬æ¢ ==========
        img_resized = cv2.resize(image, (w_tg, h_tg), interpolation=cv2.INTER_LINEAR)
        img_tensor = self.transform(image=img_resized)['image']
        
        # ========== 10. è¿”å›å®Œæ•´æ•°æ® ==========
        return {
            'image': img_tensor,  # (3, H, W)
            
            # åˆ†å‰²æ ‡ç­¾
            'baseline_mask': torch.from_numpy(baseline_resized).float(),  # (12, H, W)
            'text_mask': torch.from_numpy(text_resized).float(),          # (13, H, W)
            'wave_segmentation': torch.from_numpy(wave_seg_resized).long(),  # (H, W)
            'auxiliary_mask': torch.from_numpy(aux_resized).float(),      # (H, W)
            
            # OCR æ ‡ç­¾
            'paper_speed_mask': torch.from_numpy(ps_resized).float(),     # (H, W)
            'gain_mask': torch.from_numpy(gain_resized).float(),          # (H, W)
            
            # ä¿¡å·å›å½’æ ‡ç­¾
            'gt_signals': torch.from_numpy(target_signals).float(),       # (12, W/4)
            'valid_mask': torch.from_numpy(valid_mask).float(),           # (12, W/4)
            
            # å…ƒæ•°æ®
            'metadata': {
                'ecg_id': str(sid),
                'gain': float(gain),
                'speed': float(speed),
                'orig_size': (orig_h, orig_w)  # ğŸ”¥ æ–°å¢ï¼šåŸå§‹å›¾åƒå°ºå¯¸
            }
        }


def create_dataloaders(sim_root, csv_root, batch_size=8, num_workers=4, 
                       train_split=0.9, **kwargs):
    """
    åˆ›å»ºè®­ç»ƒå’ŒéªŒè¯ DataLoader
    """
    augment_flag = kwargs.pop('augment', None)
    cache_flag = kwargs.pop('cache_data', True)
    
    train_ds = ECGV48FixedDataset(
        sim_root, csv_root, split='train', 
        augment=True,
        cache_images=cache_flag,
        **kwargs
    )
    
    val_ds = ECGV48FixedDataset(
        sim_root, csv_root, split='val',
        augment=False,
        cache_images=cache_flag,
        **kwargs
    )
    
    dataset_size = len(train_ds)
    indices = list(range(dataset_size))
    split_idx = int(np.floor(train_split * dataset_size))
    
    np.random.seed(42)
    np.random.shuffle(indices)
    train_indices, val_indices = indices[:split_idx], indices[split_idx:]
    
    print(f"Dataset Split: Train={len(train_indices)}, Val={len(val_indices)}")
    
    train_subset = torch.utils.data.Subset(train_ds, train_indices)
    val_subset = torch.utils.data.Subset(val_ds, val_indices)
    
    worker_count = num_workers if num_workers > 0 else 0
    prefetch = 4 if worker_count > 0 else None
    
    train_loader = torch.utils.data.DataLoader(
        train_subset, batch_size=batch_size, shuffle=True,
        num_workers=worker_count, pin_memory=True, drop_last=True,
        persistent_workers=(worker_count > 0), prefetch_factor=prefetch
    )
    
    val_loader = torch.utils.data.DataLoader(
        val_subset, batch_size=batch_size, shuffle=False,
        num_workers=worker_count, pin_memory=True, drop_last=False,
        persistent_workers=(worker_count > 0), prefetch_factor=prefetch
    )
    
    return train_loader, val_loader


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser()
    parser.add_argument('--sim_root', type=str, required=True)
    parser.add_argument('--csv_root', type=str, required=True)
    args = parser.parse_args()
    
    if Path(args.sim_root).exists():
        print("Testing dataset...")
        loader, _ = create_dataloaders(
            args.sim_root, args.csv_root, 
            batch_size=2, max_samples=10
        )
        
        for batch in loader:
            print("\nBatch keys:", batch.keys())
            print(f"Image: {batch['image'].shape}")
            print(f"Baseline: {batch['baseline_mask'].shape}")
            print(f"Wave Seg: {batch['wave_segmentation'].shape}")
            print(f"Auxiliary: {batch['auxiliary_mask'].shape}")
            print(f"Signals: {batch['gt_signals'].shape}")
            print(f"Valid Mask: {batch['valid_mask'].shape}")
            
            # ğŸ”¥ éªŒè¯ä¿¡å·å¯¹é½
            for i in range(12):
                valid_ratio = batch['valid_mask'][0, i].sum() / batch['valid_mask'][0, i].numel()
                print(f"  Lead {i}: {valid_ratio:.2%} valid pixels")
            break
        
        print("\nâœ“ Dataset test passed!")