"""
ä¿®å¤ç‰ˆæŸå¤±å‡½æ•° - æ”¯æŒå¯¼è”æœ‰æ•ˆæ—¶é—´æ©ç 

å…³é”®æ”¹è¿›:
1. æ·»åŠ signal_maskå‚æ•°ï¼Œæ ‡è®°æ¯ä¸ªå¯¼è”çš„æœ‰æ•ˆæ—¶é—´æ®µ
2. åªåœ¨æœ‰æ•ˆåŒºåŸŸè®¡ç®—æŸå¤±
3. é¿å…æ¨¡å‹è¢«è¿«å­¦ä¹ å¡«å……çš„0å€¼
"""

import torch
import torch.nn as nn
import torch.nn.functional as F


class MultiTaskLossWithMask(nn.Module):
    """
    æ”¯æŒå¯¼è”æ—¶é—´æ©ç çš„å¤šä»»åŠ¡æŸå¤±å‡½æ•°
    
    æ–°å¢åŠŸèƒ½:
    - signal_mask: (B, 12, T) bool tensorï¼Œæ ‡è®°æ¯ä¸ªå¯¼è”æ¯ä¸ªæ—¶é—´ç‚¹æ˜¯å¦æœ‰æ•ˆ
    - åªåœ¨æœ‰æ•ˆåŒºåŸŸè®¡ç®—ä¿¡å·æŸå¤±
    """
    def __init__(self, loss_weights: dict = None):
        super().__init__()
        
        self.weights = loss_weights or {
            'seg': 1.0,
            'grid': 0.5,
            'baseline': 0.8,
            'theta': 0.3,
            'signal': 2.0
        }
        
        self.ce_loss = nn.CrossEntropyLoss(ignore_index=255)
        self.bce_loss = nn.BCELoss()
        self.l1_loss = nn.L1Loss(reduction='none')  # ğŸ”¥ æ”¹ä¸ºnoneï¼Œæ‰‹åŠ¨å¤„ç†mask
    
    def dice_loss(self, pred, target, num_classes):
        """å¤šç±»DiceæŸå¤±ï¼ˆä¸å˜ï¼‰"""
        pred = F.softmax(pred, dim=1)
        target_one_hot = F.one_hot(target, num_classes).permute(0, 3, 1, 2).float()
        
        intersection = (pred * target_one_hot).sum(dim=(2, 3))
        union = pred.sum(dim=(2, 3)) + target_one_hot.sum(dim=(2, 3))
        
        dice = (2.0 * intersection + 1e-7) / (union + 1e-7)
        return 1 - dice.mean()
    
    def masked_mae_loss(self, pred, target, mask):
        """
        å¸¦æ©ç çš„MAEæŸå¤±
        
        Args:
            pred: (B, 12, T)
            target: (B, 12, T)
            mask: (B, 12, T) boolï¼ŒTrueè¡¨ç¤ºæœ‰æ•ˆåŒºåŸŸ
        
        Returns:
            loss: scalar
        """
        # åªåœ¨æœ‰æ•ˆåŒºåŸŸè®¡ç®—è¯¯å·®
        mae = torch.abs(pred - target)  # (B, 12, T)
        masked_mae = mae * mask.float()  # æ— æ•ˆåŒºåŸŸç½®0
        
        # è®¡ç®—å¹³å‡æŸå¤±ï¼ˆé™¤ä»¥æœ‰æ•ˆç‚¹æ•°ï¼‰
        num_valid = mask.float().sum() + 1e-7
        loss = masked_mae.sum() / num_valid
        
        return loss
    
    def masked_pearson_loss(self, pred, target, mask):
        """
        å¸¦æ©ç çš„Pearsonç›¸å…³ç³»æ•°æŸå¤±
        
        Args:
            pred: (B, 12, T)
            target: (B, 12, T)
            mask: (B, 12, T) bool
        
        Returns:
            loss: scalar (1 - å¹³å‡ç›¸å…³ç³»æ•°)
        """
        B, num_leads, T = pred.shape
        
        correlations = []
        
        for b in range(B):
            for lead in range(num_leads):
                lead_mask = mask[b, lead]  # (T,)
                
                # è·³è¿‡å®Œå…¨æ— æ•ˆçš„å¯¼è”
                if lead_mask.sum() < 10:  # è‡³å°‘éœ€è¦10ä¸ªæœ‰æ•ˆç‚¹
                    continue
                
                # æå–æœ‰æ•ˆåŒºåŸŸ
                pred_valid = pred[b, lead, lead_mask]  # (N_valid,)
                target_valid = target[b, lead, lead_mask]  # (N_valid,)
                
                # è®¡ç®—Pearsonç›¸å…³ç³»æ•°
                pred_mean = pred_valid.mean()
                target_mean = target_valid.mean()
                
                pred_centered = pred_valid - pred_mean
                target_centered = target_valid - target_mean
                
                numerator = (pred_centered * target_centered).sum()
                pred_std = torch.sqrt((pred_centered ** 2).sum() + 1e-6)
                target_std = torch.sqrt((target_centered ** 2).sum() + 1e-6)
                denominator = pred_std * target_std + 1e-6
                
                corr = numerator / denominator
                corr = torch.clamp(corr, -1.0, 1.0)
                
                correlations.append(corr)
        
        if len(correlations) == 0:
            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆå¯¼è”ï¼Œè¿”å›æœ€å¤§æŸå¤±
            return torch.tensor(1.0, device=pred.device)
        
        # è¿”å›è´Ÿå¹³å‡ç›¸å…³ç³»æ•°
        avg_corr = torch.stack(correlations).mean()
        return 1 - avg_corr
    
    def forward(self, outputs, targets):
        """
        Args:
            outputs: dict from model
                - wave_seg: (B, 13, H, W)
                - grid_mask: (B, 1, H, W)
                - baseline_heatmaps: (B, 12, H/16, W/16)
                - theta: (B, 2, 3)
                - signal: (B, 12, T)
            
            targets: dict containing
                - wave_seg: (B, H, W)
                - grid_mask: (B, 1, H, W)
                - baseline_heatmaps: (B, 12, H, W)
                - theta_gt: (B, 2, 3)
                - gt_signal: (B, T, 12)
                - signal_mask: (B, T, 12) bool [æ–°å¢]
        """
        losses = {}
        
        # ========== 1-4. åˆ†å‰²/ç½‘æ ¼/åŸºçº¿/å‡ ä½•æŸå¤±ï¼ˆä¸å˜ï¼‰==========
        wave_seg_pred = outputs['wave_seg']
        wave_seg_target = targets['wave_seg']
        
        ce_seg = self.ce_loss(wave_seg_pred, wave_seg_target)
        dice_seg = self.dice_loss(wave_seg_pred, wave_seg_target, num_classes=13)
        losses['seg'] = (ce_seg + dice_seg) * self.weights['seg']
        
        grid_pred = outputs['grid_mask']
        grid_target = targets['grid_mask']
        bce_grid = self.bce_loss(grid_pred, grid_target)
        intersection = (grid_pred * grid_target).sum()
        union = grid_pred.sum() + grid_target.sum()
        dice_grid = 1 - (2.0 * intersection + 1e-7) / (union + 1e-7)
        losses['grid'] = (bce_grid + dice_grid) * self.weights['grid']
        
        baseline_pred = outputs['baseline_heatmaps']
        baseline_target = targets['baseline_heatmaps']
        B, num_leads, H_pred, W_pred = baseline_pred.shape
        baseline_target_down = F.interpolate(
            baseline_target, size=(H_pred, W_pred),
            mode='bilinear', align_corners=True
        )
        losses['baseline'] = self.bce_loss(baseline_pred, baseline_target_down) * self.weights['baseline']
        
        if 'theta' in outputs and outputs['theta'] is not None:
            theta_pred = outputs['theta']
            theta_target = targets['theta_gt']
            losses['theta'] = torch.nn.functional.l1_loss(theta_pred, theta_target) * self.weights['theta']
        else:
            losses['theta'] = torch.tensor(0.0, device=baseline_pred.device)
        
        # ========== 5. ä¿¡å·é‡å»ºæŸå¤±ï¼ˆä¿®å¤ç‰ˆï¼‰==========
        signal_pred = outputs['signal']  # (B, 12, T)
        signal_target = targets['gt_signal'].transpose(1, 2)  # (B, 12, T)
        signal_mask = targets['signal_mask'].transpose(1, 2)  # (B, 12, T)
        
        # å½’ä¸€åŒ–ï¼ˆåªåœ¨æœ‰æ•ˆåŒºåŸŸï¼‰
        signal_pred_norm = self._normalize_signal_masked(signal_pred, signal_mask)
        signal_target_norm = self._normalize_signal_masked(signal_target, signal_mask)
        
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šä½¿ç”¨æ©ç æŸå¤±
        mae_signal = self.masked_mae_loss(signal_pred_norm, signal_target_norm, signal_mask)
        corr_signal = self.masked_pearson_loss(signal_pred_norm, signal_target_norm, signal_mask)
        
        losses['signal'] = (mae_signal + corr_signal) * self.weights['signal']
        
        # ========== æ€»æŸå¤± ==========
        total_loss = sum(losses.values())
        losses['total'] = total_loss
        
        return losses
    
    def _normalize_signal_masked(self, signal, mask):
        """
        å¯¹æ¯ä¸ªå¯¼è”åœ¨æœ‰æ•ˆåŒºåŸŸç‹¬ç«‹å½’ä¸€åŒ–
        
        Args:
            signal: (B, 12, T)
            mask: (B, 12, T) bool
        
        Returns:
            signal_norm: (B, 12, T)
        """
        B, num_leads, T = signal.shape
        signal_norm = torch.zeros_like(signal)
        
        for b in range(B):
            for lead in range(num_leads):
                lead_mask = mask[b, lead]
                
                if lead_mask.sum() < 2:  # è‡³å°‘2ä¸ªç‚¹æ‰èƒ½å½’ä¸€åŒ–
                    continue
                
                # åªåœ¨æœ‰æ•ˆåŒºåŸŸè®¡ç®—min/max
                valid_signal = signal[b, lead, lead_mask]
                min_val = valid_signal.min()
                max_val = valid_signal.max()
                
                if max_val - min_val < 1e-6:  # å¸¸æ•°ä¿¡å·
                    signal_norm[b, lead] = 0.0
                else:
                    # å½’ä¸€åŒ–åˆ°[-1, 1]
                    signal_norm[b, lead] = 2 * (signal[b, lead] - min_val) / (max_val - min_val + 1e-8) - 1
                    
                    # æ— æ•ˆåŒºåŸŸç½®0ï¼ˆå¯é€‰ï¼Œå› ä¸ºæŸå¤±è®¡ç®—ä¼šå¿½ç•¥ï¼‰
                    signal_norm[b, lead, ~lead_mask] = 0.0
        
        return signal_norm


# ========== æµ‹è¯•ä»£ç  ==========
if __name__ == "__main__":
    print("="*70)
    print("å¸¦æ©ç çš„æŸå¤±å‡½æ•°æµ‹è¯•")
    print("="*70)
    
    loss_fn = MultiTaskLossWithMask()
    
    B, H, W, T = 2, 512, 672, 5000
    
    outputs = {
        'wave_seg': torch.randn(B, 13, H, W, requires_grad=True),
        'grid_mask': torch.sigmoid(torch.randn(B, 1, H, W, requires_grad=True)),
        'baseline_heatmaps': torch.sigmoid(torch.randn(B, 12, H//16, W//16, requires_grad=True)),
        'theta': torch.randn(B, 2, 3, requires_grad=True),
        'signal': torch.randn(B, 12, T, requires_grad=True)
    }
    
    # ğŸ”¥ æ¨¡æ‹ŸçœŸå®æ©ç ï¼šIIå¯¼è”å…¨æ—¶é—´ï¼Œå…¶ä»–å¯¼è”éƒ¨åˆ†æ—¶é—´
    signal_mask = torch.zeros(B, T, 12, dtype=torch.bool)
    
    # IIå¯¼è”ï¼ˆç´¢å¼•1ï¼‰ï¼šå®Œæ•´10ç§’
    signal_mask[:, :, 1] = True
    
    # å…¶ä»–å¯¼è”ï¼šåªæœ‰2.5-5.0ç§’æœ‰æ•°æ®
    signal_mask[:, 1250:2500, [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]] = True
    
    print(f"\næ©ç ç»Ÿè®¡:")
    for lead in range(12):
        valid_ratio = signal_mask[:, :, lead].float().mean().item()
        print(f"  Lead {lead:2d}: {valid_ratio*100:.1f}% æœ‰æ•ˆ")
    
    targets = {
        'wave_seg': torch.randint(0, 13, (B, H, W)),
        'grid_mask': torch.rand(B, 1, H, W),
        'baseline_heatmaps': torch.rand(B, 12, H, W),
        'theta_gt': torch.randn(B, 2, 3),
        'gt_signal': torch.randn(B, T, 12),
        'signal_mask': signal_mask  # ğŸ”¥ æ–°å¢
    }
    
    # è®¡ç®—æŸå¤±
    losses = loss_fn(outputs, targets)
    
    print("\næŸå¤±å€¼:")
    for key, value in losses.items():
        print(f"  {key:15s}: {value.item():.4f}")
    
    # æµ‹è¯•åå‘ä¼ æ’­
    print("\næµ‹è¯•åå‘ä¼ æ’­...")
    losses['total'].backward()
    print("âœ“ åå‘ä¼ æ’­æˆåŠŸ")
    
    print("\n" + "="*70)
    print("âœ“ æµ‹è¯•é€šè¿‡ï¼")
    print("="*70)